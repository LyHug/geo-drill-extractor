#!/usr/bin/env python3
# -*- coding:utf-8 -*-
"""
ç›´æ¥è¿è¡Œ7ä¸ªæ ¸å¿ƒæ¨¡å‹å®Œæ•´æµ‹è¯•çš„ç®€å•è„šæœ¬
é…ç½®ï¼š7ä¸ªæ¨¡å‹ + 30ä¸ªæ–‡æ¡£ + 3è½®é‡å¤ + æµå¼è¾“å‡º
æ”¯æŒçš„æ¨¡å‹ï¼šDeepSeek R1ç³»åˆ—ã€GPTç³»åˆ—ã€Qwenç³»åˆ—
"""



import sys
from pathlib import Path
import time
from datetime import datetime

# æ·»åŠ srcç›®å½•åˆ°Pythonè·¯å¾„
src_path = Path(__file__).parent / "src"
sys.path.insert(0, str(src_path))

from kg_drill_extraction.experiment import ExperimentRunner
from kg_drill_extraction.core import LLMModel



def main():
    """ä¸»å‡½æ•° - ç›´æ¥è¿è¡Œå®Œæ•´æµ‹è¯•"""
    print("ğŸš€ KGé’»å­”æå–ç³»ç»Ÿ - 7ä¸ªæ ¸å¿ƒæ¨¡å‹å®Œæ•´æµ‹è¯•")
    print("="*50)
    print("âš™ï¸  æµ‹è¯•é…ç½®: 7ä¸ªæ¨¡å‹ Ã— 30ä¸ªæ–‡æ¡£ Ã— 3è½®é‡å¤")
    print(f"ğŸ• å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print()

    start_time = time.time()

    try:
        # è·å–æ‰€æœ‰æ¨¡å‹å¹¶åˆ›å»ºå®éªŒæ‰§è¡Œå™¨
        all_models = list(LLMModel)
        target_values = [
                        'deepseek-r1-distill-qwen-7b-aliyun',
                        'deepseek-r1-distill-qwen-14b-aliyun',
                        'deepseek-r1-distill-qwen-32b-aliyun',
                        'gpt-3.5-turbo-openrouter',
                        'gpt-4o-mini-openrouter',
                        'qwen-max',
                        'qwq-32b'
                         ]
        experiment_models = [
            model for model in all_models if model.value in target_values]
        print(f"ğŸ¤– åŠ è½½ {len(experiment_models)} ä¸ªå®éªŒæ¨¡å‹...")

        runner = ExperimentRunner(models=experiment_models, stream_mode=True)

        # è¿è¡Œå®éªŒ
        print("ğŸ“Š å¼€å§‹æ‰§è¡Œå®éªŒ...")
        results = runner.run_experiment(
            repetitions=3,
            test_documents=30,
            save_results=True
        )

        # è®¡ç®—æ—¶é—´
        elapsed_time = time.time() - start_time

        # æ˜¾ç¤ºç»“æœ
        print("\n" + "="*50)
        print("ğŸ‰ æµ‹è¯•å®Œæˆï¼")

        metadata = results.get('metadata', {})
        statistics = results.get('statistics', {})

        successful_runs = statistics.get('successful_runs', 0)
        failed_runs = statistics.get('failed_runs', 0)
        success_rate = (successful_runs /
                        max(successful_runs + failed_runs, 1)) * 100

        print(f"â±ï¸  æ€»æ—¶é—´: {elapsed_time/60:.1f} åˆ†é’Ÿ")
        print(
            f"ğŸ“Š æˆåŠŸç‡: {success_rate:.1f}% ({successful_runs}/{successful_runs + failed_runs})")
        print(f"ğŸ“„ æ–‡æ¡£æ•°: {metadata.get('total_documents', 0)}")
        print(f"ğŸ¤– æ¨¡å‹æ•°: {len(metadata.get('models', []))}")

        # æ˜¾ç¤ºè¾“å‡ºç›®å½•
        raw_results = results.get('raw_results', {})
        if raw_results:
            for model_data in raw_results.values():
                if isinstance(model_data, dict) and 'output_dir' in model_data:
                    output_dir = Path(model_data['output_dir']).parent
                    print(f"ğŸ“ ç»“æœ: {output_dir}")
                    break

        if success_rate >= 90:
            print("âœ… æµ‹è¯•æˆåŠŸï¼")
        else:
            print("âš ï¸  éƒ¨åˆ†æµ‹è¯•å¤±è´¥")

    except KeyboardInterrupt:
        print(f"\nâ¹ï¸  æµ‹è¯•ä¸­æ–­ (è¿è¡Œæ—¶é—´: {(time.time() - start_time)/60:.1f}åˆ†é’Ÿ)")
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {str(e)}")
        return 1

    return 0


if __name__ == "__main__":
    sys.exit(main())
